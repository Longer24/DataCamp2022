{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "#  Home Task: Sklearn SVM for Iris dataset\n",
    "</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear kernel:\n",
      "train accuracy= 97.500%\n",
      "test accuracy= 96.667%\n",
      "\n",
      "Poly kernel:\n",
      "train accuracy= 98.333%\n",
      "test accuracy= 93.333%\n",
      "\n",
      "RBF kernel:\n",
      "train accuracy= 98.333%\n",
      "test accuracy= 93.333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\2371416088.py:24: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_train = y[:n_train]\n",
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\2371416088.py:26: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  y_test = y[n_train:]\n"
     ]
    }
   ],
   "source": [
    "# YOUR_CODE.  Try linear, rbf and poly kernels \n",
    "# START_CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "import math\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# import iris dataset\n",
    "iris = datasets.load_iris()\n",
    "# np.c_ is the numpy concatenate function\n",
    "df_iris = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                      columns= iris['feature_names'] + ['target'])\n",
    "df_iris = df_iris.sample(frac = 1, random_state=3)\n",
    "X= df_iris.iloc[:, :-1]\n",
    "y= df_iris.iloc[:, -1]\n",
    "\n",
    "n_train = math.floor(0.8 * X.shape[0])\n",
    "n_test = math.ceil((0.2) * X.shape[0])\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]\n",
    "\n",
    "X_train= np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "X_test= np.asarray(X_test)\n",
    "y_test= np.asarray(y_test)\n",
    "scaler= Normalizer().fit(X_train) # the scaler is fitted to the training set\n",
    "X_train_scaled= scaler.transform(X_train) # the scaler is applied to the training set\n",
    "X_test_scaled= scaler.transform(X_test) # the scaler is applied to the test set\n",
    "y_train = np.squeeze(y_train) # LogisticRegression requires 1d input for y\n",
    "\n",
    "# Linear kernel\n",
    "clf_svm_lin = SVC (C=10, kernel='linear').fit (X_train_scaled, y_train)\n",
    "print(\"\\nLinear kernel:\")\n",
    "print(\"train accuracy= {:.3%}\".format(clf_svm_lin.score (X_train_scaled, y_train)))\n",
    "print(\"test accuracy= {:.3%}\".format(clf_svm_lin.score (X_test_scaled, y_test)))\n",
    "\n",
    "# Poly kernel\n",
    "clf_svm_poly = SVC (C=10, kernel='poly', degree=3).fit (X_train_scaled, y_train)\n",
    "print(\"\\nPoly kernel:\")\n",
    "print(\"train accuracy= {:.3%}\".format(clf_svm_poly.score (X_train_scaled, y_train)))\n",
    "print(\"test accuracy= {:.3%}\".format(clf_svm_poly.score (X_test_scaled, y_test)))\n",
    "\n",
    "# RBF kernel\n",
    "clf_svm_rbf = SVC (C=10, kernel='rbf', gamma=0.2).fit (X_train_scaled, y_train)\n",
    "print(\"\\nRBF kernel:\")\n",
    "print(\"train accuracy= {:.3%}\".format(clf_svm_rbf.score (X_train_scaled, y_train)))\n",
    "print(\"test accuracy= {:.3%}\".format(clf_svm_rbf.score (X_test_scaled, y_test)))\n",
    "\n",
    "# END_CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font color = green>\n",
    "\n",
    "##  Spam/Non-spam classification\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color = green>\n",
    "\n",
    "### Reveiw sample mail \n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_sample(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "cwd= os.getcwd()\n",
    "path = os.path.join(cwd,'data') \n",
    "fn=  os.path.join(path , 'emailSample1.txt')\n",
    "content = get_sample(fn)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Word tokenization\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokeniize(content):\n",
    "    '''\n",
    "    content: str - body of mail \n",
    "    return: list of tokens (str) e.g. ['>', 'Anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a']\n",
    "    '''\n",
    "    # YOUR_CODE.  Split the content to tokens. You may need re.split()\n",
    "    # START_CODE \n",
    "    tokens = np.array(re.split('[ \\n^]', content))\n",
    "\n",
    "    # END_CODE \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['>', 'Anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host',\n",
       "       'a', 'web', 'portal', '?', '>', 'Well,', 'it', 'depends', 'on',\n",
       "       'how', 'many', 'visitors', \"you're\", 'expecting.', 'This', 'can',\n",
       "       'be', 'anywhere', 'from', 'less', 'than', '10', 'bucks', 'a',\n",
       "       'month', 'to', 'a', 'couple', 'of', '$100.', '', 'You', 'should',\n",
       "       'checkout', 'http://www.rackspace.com/', 'or', 'perhaps', 'Amazon',\n",
       "       'EC2', '', 'if', 'youre', 'running', 'something', 'big..', '',\n",
       "       'To', 'unsubscribe', 'yourself', 'from', 'this', 'mailing',\n",
       "       'list,', 'send', 'an', 'email', 'to:',\n",
       "       'groupname-unsubscribe@egroups.com', '', ''], dtype='<U33')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens  = word_tokeniize('''> Anyone knows how much it costs to host a web portal ?\\n>\\nWell, it depends on how many visitors you're expecting.\\nThis can be anywhere from less than 10 bucks a month to a couple of $100. \\nYou should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \\nif youre running something big..\\n\\nTo unsubscribe yourself from this mailing list, send an email to:\\ngroupname-unsubscribe@egroups.com\\n\\n''')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`array(['>', 'Anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host',\n",
    "       'a', 'web', 'portal', '?', '>', 'Well', 'it', 'depends', 'on',\n",
    "       'how', 'many', 'visitors', \"you're\", 'expecting.', 'This', 'can',\n",
    "       'be', 'anywhere', 'from', 'less', 'than', '10', 'bucks', 'a',\n",
    "       'month', 'to', 'a', 'couple', 'of', '$100.', '', 'You', 'should',\n",
    "       'checkout', 'http://www.rackspace.com/', 'or', 'perhaps', 'Amazon',\n",
    "       'EC2', '', 'if', 'youre', 'running', 'something', 'big..', '',\n",
    "       'To', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list',\n",
    "       'send', 'an', 'email', 'to:', 'groupname-unsubscribe@egroups.com',\n",
    "       '', ''], dtype='<U33')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Lower case \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of tokens in lower case (str)\n",
    "    '''\n",
    "    # YOUR_CODE.  Make all tokens in lower case\n",
    "    # START_CODE \n",
    "    tokens= np.char.lower(tokens)\n",
    "    # END_CODE \n",
    "   \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['>', 'anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host',\n",
       "       'a', 'web', 'portal', '?', '>', 'well,', 'it', 'depends', 'on',\n",
       "       'how', 'many', 'visitors', \"you're\", 'expecting.', 'this', 'can',\n",
       "       'be', 'anywhere', 'from', 'less', 'than', '10', 'bucks', 'a',\n",
       "       'month', 'to', 'a', 'couple', 'of', '$100.', '', 'you', 'should',\n",
       "       'checkout', 'http://www.rackspace.com/', 'or', 'perhaps', 'amazon',\n",
       "       'ec2', '', 'if', 'youre', 'running', 'something', 'big..', '',\n",
       "       'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing',\n",
       "       'list,', 'send', 'an', 'email', 'to:',\n",
       "       'groupname-unsubscribe@egroups.com', '', ''], dtype='<U33')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = lower_case(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`array(['>', 'anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host',\n",
    "       'a', 'web', 'portal', '?', '>', 'well', 'it', 'depends', 'on',\n",
    "       'how', 'many', 'visitors', \"you're\", 'expecting.', 'this', 'can',\n",
    "       'be', 'anywhere', 'from', 'less', 'than', '10', 'bucks', 'a',\n",
    "       'month', 'to', 'a', 'couple', 'of', '$100.', '', 'you', 'should',\n",
    "       'checkout', 'http://www.rackspace.com/', 'or', 'perhaps', 'amazon',\n",
    "       'ec2', '', 'if', 'youre', 'running', 'something', 'big..', '',\n",
    "       'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list',\n",
    "       'send', 'an', 'email', 'to:', 'groupname-unsubscribe@egroups.com',\n",
    "       '', ''], dtype='<U33')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Normalize\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tokens (tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of tokens replaced with corresponding unified words\n",
    "    '''\n",
    "    # YOUR_CODE.  \n",
    "        # Remove html and other tags\n",
    "        # mark all numbers \"number\"\n",
    "        # mark all  urls as \"httpaddr\"\n",
    "        # mark all emails as \"emailaddr\"\n",
    "        # replace $ as \"dollar\"\n",
    "        # get rid of any punctuation\n",
    "        # Remove any non alphanumeric characters\n",
    "    #  You may  need re.sub()\n",
    "    # START_CODE \n",
    "    tokens = np.array([re.sub('<[^<]+?>', '', token) for token in tokens])\n",
    "    tokens = np.array([re.sub('[0-9]{1,100}', 'number', token) for token in tokens])\n",
    "    tokens = np.array([re.sub('^https?:\\/\\/(.*)', 'httpaddr', token) for token in tokens])\n",
    "    tokens = np.array([re.sub('[a-z0-9+._-]+@[a-z0-9._-]+\\.[a-z0-9_-]+', 'emailaddr', token) for token in tokens])\n",
    "    tokens = np.array([re.sub('[$]', 'dollar', token) for token in tokens])\n",
    "    tokens = np.array([re.sub('[^\\w\\s]', '', token) for token in tokens])\n",
    "    # END_CODE \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host',\n",
       "       'a', 'web', 'portal', '', '', 'well', 'it', 'depends', 'on', 'how',\n",
       "       'many', 'visitors', 'youre', 'expecting', 'this', 'can', 'be',\n",
       "       'anywhere', 'from', 'less', 'than', 'number', 'bucks', 'a',\n",
       "       'month', 'to', 'a', 'couple', 'of', 'dollarnumber', '', 'you',\n",
       "       'should', 'checkout', 'httpaddr', 'or', 'perhaps', 'amazon',\n",
       "       'ecnumber', '', 'if', 'youre', 'running', 'something', 'big', '',\n",
       "       'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list',\n",
       "       'send', 'an', 'email', 'to', 'emailaddr', '', ''], dtype='<U12')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = normalize_tokens(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`array(['', 'anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host',\n",
    "       'a', 'web', 'portal', '', '', 'well', 'it', 'depends', 'on', 'how',\n",
    "       'many', 'visitors', 'youre', 'expecting', 'this', 'can', 'be',\n",
    "       'anywhere', 'from', 'less', 'than', 'number', 'bucks', 'a',\n",
    "       'month', 'to', 'a', 'couple', 'of', 'dollarnumber', '', 'you',\n",
    "       'should', 'checkout', 'httpaddr', 'or', 'perhaps', 'amazon',\n",
    "       'ecnumber', '', 'if', 'youre', 'running', 'something', 'big', '',\n",
    "       'to', 'unsubscribe', 'yourself', 'from', 'this', 'mailing', 'list',\n",
    "       'send', 'an', 'email', 'to', 'emailaddr', '', ''], dtype='<U12')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Remove zero length tokens\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_tokens (tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of filtered tokens (str)\n",
    "    '''\n",
    "    original_tokens_len = len(tokens)\n",
    "    \n",
    "    # YOUR_CODE. Keep only tokens that lenght >0  \n",
    "    # START_CODE \n",
    "    tokens = tokens[np.where(tokens != '')]\n",
    "    # END_CODE     \n",
    "   \n",
    "    print ('Original len= {}\\nRemaining len= {}'.format(original_tokens_len, len(tokens)))    \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len= 69\n",
      "Remaining len= 61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a',\n",
       "       'web', 'portal', 'well', 'it', 'depends', 'on', 'how', 'many',\n",
       "       'visitors', 'youre', 'expecting', 'this', 'can', 'be', 'anywhere',\n",
       "       'from', 'less', 'than', 'number', 'bucks', 'a', 'month', 'to', 'a',\n",
       "       'couple', 'of', 'dollarnumber', 'you', 'should', 'checkout',\n",
       "       'httpaddr', 'or', 'perhaps', 'amazon', 'ecnumber', 'if', 'youre',\n",
       "       'running', 'something', 'big', 'to', 'unsubscribe', 'yourself',\n",
       "       'from', 'this', 'mailing', 'list', 'send', 'an', 'email', 'to',\n",
       "       'emailaddr'], dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = filter_short_tokens(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`Original len= 69\n",
    "Remaining len= 61\n",
    "array(['anyone', 'knows', 'how', 'much', 'it', 'costs', 'to', 'host', 'a',\n",
    "       'web', 'portal', 'well', 'it', 'depends', 'on', 'how', 'many',\n",
    "       'visitors', 'youre', 'expecting', 'this', 'can', 'be', 'anywhere',\n",
    "       'from', 'less', 'than', 'number', 'bucks', 'a', 'month', 'to', 'a',\n",
    "       'couple', 'of', 'dollarnumber', 'you', 'should', 'checkout',\n",
    "       'httpaddr', 'or', 'perhaps', 'amazon', 'ecnumber', 'if', 'youre',\n",
    "       'running', 'something', 'big', 'to', 'unsubscribe', 'yourself',\n",
    "       'from', 'this', 'mailing', 'list', 'send', 'an', 'email', 'to',\n",
    "       'emailaddr'], dtype='<U12')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Stem tokens\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of stemmed tokens e.g. array(['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a',\n",
    "       'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani']...\n",
    "    '''\n",
    "    # YOUR_CODE. replace the tokens by stemmed form. You may need PorterStemmer.stem() \n",
    "    # START_CODE \n",
    "    \n",
    "    tokens= np.array([PorterStemmer().stem(token) for token in tokens])   \n",
    "    \n",
    "    # END_CODE     \n",
    "   \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a',\n",
       "       'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani',\n",
       "       'visitor', 'your', 'expect', 'thi', 'can', 'be', 'anywher', 'from',\n",
       "       'less', 'than', 'number', 'buck', 'a', 'month', 'to', 'a', 'coupl',\n",
       "       'of', 'dollarnumb', 'you', 'should', 'checkout', 'httpaddr', 'or',\n",
       "       'perhap', 'amazon', 'ecnumb', 'if', 'your', 'run', 'someth', 'big',\n",
       "       'to', 'unsubscrib', 'yourself', 'from', 'thi', 'mail', 'list',\n",
       "       'send', 'an', 'email', 'to', 'emailaddr'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = stem_tokens(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`array(['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a',\n",
    "       'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani',\n",
    "       'visitor', 'your', 'expect', 'thi', 'can', 'be', 'anywher', 'from',\n",
    "       'less', 'than', 'number', 'buck', 'a', 'month', 'to', 'a', 'coupl',\n",
    "       'of', 'dollarnumb', 'you', 'should', 'checkout', 'httpaddr', 'or',\n",
    "       'perhap', 'amazon', 'ecnumb', 'if', 'your', 'run', 'someth', 'big',\n",
    "       'to', 'unsubscrib', 'yourself', 'from', 'thi', 'mail', 'list',\n",
    "       'send', 'an', 'email', 'to', 'emailaddr'], dtype='<U10')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Vocabulary\n",
    "</font>\n",
    "\n",
    "Ususally vocabulary is built from the top most frequent tokens within all available training set.\n",
    "For this task it is already prepared and provided in the `vocab.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab)= 1,899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['aa', 'ab', 'abil', ..., 'zdnet', 'zero', 'zip'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vocabulary(fn):\n",
    "    '''\n",
    "    fn: str - full path to file \n",
    "    return: ndarray of str e.g. array(['aa', 'ab', 'abil', ..., 'zdnet', 'zero', 'zip'], dtype=object)\n",
    "    '''\n",
    "    vocab_list = pd.read_table(fn, header=None)\n",
    "    vocab = np.array(vocab_list)[:,1]  \n",
    "    print ('len(vocab)= {:,}'.format(len(vocab)))\n",
    "    return vocab\n",
    "\n",
    "fn=  os.path.join(path , 'vocab.txt')\n",
    "vocab = get_vocabulary(fn)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Feature reresentation\n",
    "</font>\n",
    "\n",
    "Every word in vocabulary is the feature of the mail - 1 is the word in in the mail and 0 otherwise. \n",
    "Thus every mail can be represented as the binary array of fixed length - number of words in vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_features(tokens,vocab):\n",
    "    '''\n",
    "    tokens: ndarry of str\n",
    "    tokens: ndarry of str\n",
    "    return: ndarry of binary values 1 if word from vocabulary is in mail 0 otherwise\n",
    "    '''\n",
    "    # YOUR_CODE. Compute the array with 1/0 corresponding to is word from vocabulary in mail \n",
    "    # START_CODE \n",
    "    tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n",
    "    # END_CODE     \n",
    "\n",
    "    print ('{} word(s) from vocab are in the tokens.'.format(np.sum(tokens_represented)))\n",
    "\n",
    "   \n",
    "    return tokens_represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 word(s) from vocab are in the tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\600396973.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_represented = represent_features(tokens, vocab)\n",
    "tokens_represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`44 word(s) from vocab are in the tokens.\n",
    "array([0, 0, 0, ..., 0, 0, 0])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Composing all steps of preprocessing \n",
    "</font>\n",
    "\n",
    "Every word in vocabulary is the feature of the mail - 1 is the word in in the mail and 0 otherwise. \n",
    "Thus every mail can be represented as the binary array of fixed length - number of words in vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (content,vocab):\n",
    "    '''\n",
    "    content: str - body of mail \n",
    "    vocab: ndarray of str - list of considered words \n",
    "    '''\n",
    "    # YOUR_CODE. Compute the array with 1/0 corresponding to is word from vocabulary in mail \n",
    "    # START_CODE \n",
    "\n",
    "    # tokenize content    \n",
    "    tokens  = word_tokeniize(content)\n",
    "    \n",
    "    # make lower case\n",
    "    tokens = lower_case(tokens)\n",
    "\n",
    "    # normalize tokens\n",
    "    tokens = normalize_tokens (tokens)\n",
    "\n",
    "    # remove zero words\n",
    "    tokens = filter_short_tokens (tokens)\n",
    "    \n",
    "    # stem words\n",
    "    tokens = stem_tokens(tokens)\n",
    "    \n",
    "    # convert to binary array of features  \n",
    "    tokens_represented = represent_features(tokens,vocab)\n",
    "    # END_CODE     \n",
    "    \n",
    "    return tokens_represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len= 69\n",
      "Remaining len= 61\n",
      "44 word(s) from vocab are in the tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\600396973.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess (content,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`Original len= 69\n",
    "Remaining len= 61\n",
    "44 word(s) from vocab are in the tokens.\n",
    "array([0, 0, 0, ..., 0, 0, 0])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Training and test sets\n",
    "</font>\n",
    "\n",
    "All mails for training are preprocessed the same way as performed for sample above. \n",
    "The training set (array of feature representation) is provided in the `spamTrain.mat`\n",
    "The corresponding test set is provided in the `spamTest.mat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= {} (4000, 1899)\n",
      "y_train.shape= {} (4000,)\n",
      "X_test.shape= {} (1000, 1899)\n",
      "y_test.shape= {} (1000,)\n",
      "Sample with index  =0: \n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "fn=  os.path.join(path , 'spamTrain.mat')\n",
    "\n",
    "mat= loadmat(fn)\n",
    "X_train= mat['X']\n",
    "y_train= mat['y'].ravel()\n",
    "\n",
    "print ('X_train.shape= {}',X_train.shape)\n",
    "print ('y_train.shape= {}',y_train.shape)\n",
    "\n",
    "fn=  os.path.join(path , 'spamTest.mat')\n",
    "mat= loadmat(fn)\n",
    "X_test = mat['Xtest']\n",
    "y_test = mat['ytest'].ravel() \n",
    "\n",
    "print ('X_test.shape= {}',X_test.shape)\n",
    "print ('y_test.shape= {}',y_test.shape)\n",
    "index = 0 \n",
    "print ('Sample with index  ={}: \\n{}'.format(index, X_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Training  the model\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score train= 0.99975\n",
      "Score test= 0.992\n"
     ]
    }
   ],
   "source": [
    "C = .1\n",
    "clf= LinearSVC(C=C)\n",
    "clf.fit(X_train,y_train)\n",
    "print ('Score train= {}'.format(clf.score(X_train,y_train)))\n",
    "print ('Score test= {}'.format(clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Determining most spam contributors\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR_CODE. Compute top 20 largest coeficients and return the corresponding 20 words from vocabulary\n",
    "# START_CODE \n",
    "coef = pd.Series(clf.coef_[0], index=vocab)\n",
    "top_spam_contributors = list(coef.sort_values(ascending=False).index[:20])\n",
    "# END_CODE    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Check result\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['our', 'remov', 'click', 'basenumb', 'guarante', 'visit', 'bodi', 'will', 'numberb', 'price', 'dollar', 'nbsp', 'below', 'lo', 'most', 'send', 'dollarnumb', 'credit', 'wi', 'hour']\n"
     ]
    }
   ],
   "source": [
    "print (top_spam_contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`['our' 'remov' 'click' 'basenumb' 'guarante' 'visit' 'bodi' 'will'\n",
    " 'numberb' 'price' 'dollar' 'nbsp' 'below' 'lo' 'most' 'send' 'dollarnumb'\n",
    " 'credit' 'wi' 'hour']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "### Use model for prediction \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original len= 69\n",
      "Remaining len= 61\n",
      "44 word(s) from vocab are in the tokens.\n",
      "emailSample1.txt is Not Spam\n",
      "\n",
      "Original len= 247\n",
      "Remaining len= 222\n",
      "122 word(s) from vocab are in the tokens.\n",
      "emailSample2.txt is Not Spam\n",
      "\n",
      "Original len= 141\n",
      "Remaining len= 97\n",
      "46 word(s) from vocab are in the tokens.\n",
      "spamSample1.txt is Spam\n",
      "\n",
      "Original len= 39\n",
      "Remaining len= 31\n",
      "18 word(s) from vocab are in the tokens.\n",
      "spamSample2.txt is Spam\n",
      "\n",
      "Latter sample:\n",
      "==================================================\n",
      "Best Buy Viagra Generic Online\n",
      "\n",
      "Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100% Quality & Satisfaction guaranteed!\n",
      "\n",
      "We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
      "http://medphysitcstech.ru\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\600396973.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n",
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\600396973.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n",
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\600396973.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n",
      "C:\\Users\\longe\\AppData\\Local\\Temp\\ipykernel_12584\\600396973.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  tokens_represented = np.array([1 if token in tokens else 0 for token in vocab])\n"
     ]
    }
   ],
   "source": [
    "for sfn in [ 'emailSample1.txt', 'emailSample2.txt', 'spamSample1.txt', 'spamSample2.txt']:\n",
    "    fn=  os.path.join(path,sfn)    \n",
    "    content = get_sample(fn)\n",
    "    \n",
    "    # YOUR_CODE.  Preprocess the sample and get prediction 0 or 1 (1 is spam)\n",
    "    # START_CODE \n",
    "    prediction = clf.predict([preprocess(content,vocab)])[0]\n",
    "    # END_CODE    \n",
    "    \n",
    "    print ('{} is {}\\n'.format(sfn, ('Not Spam','Spam')[prediction]))\n",
    "\n",
    "print ('Latter sample:\\n{1}\\n{0}\\n{1}'.format(content, '='*50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue >\n",
    "\n",
    "### Expected output\n",
    "\n",
    "</font>\n",
    "\n",
    "`Original len= 69\n",
    "Remaining len= 61\n",
    "44 word(s) from vocab are in the tokens.\n",
    "emailSample1.txt is Not Spam`\n",
    "\n",
    "`Original len= 247\n",
    "Remaining len= 222\n",
    "122 word(s) from vocab are in the tokens.\n",
    "emailSample2.txt is Not Spam`\n",
    "\n",
    "`Original len= 141\n",
    "Remaining len= 97\n",
    "46 word(s) from vocab are in the tokens.\n",
    "spamSample1.txt is Spam`\n",
    "\n",
    "`Original len= 39\n",
    "Remaining len= 31\n",
    "18 word(s) from vocab are in the tokens.\n",
    "spamSample2.txt is Spam`\n",
    "\n",
    "`Latter sample:`\n",
    "\n",
    "`==================================================`\n",
    "\n",
    "`Best Buy Viagra Generic Online`\n",
    "\n",
    "`Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100\\% Quality & Satisfaction guaranteed!`\n",
    "\n",
    "`We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
    "http://medphysitcstech.ru`\n",
    "\n",
    "\n",
    "`==================================================`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
